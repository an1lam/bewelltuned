<!DOCTYPE html>
<html>
<head>
<meta charset="utf-8" />
<title>Track Reality With Beliefs: Outline</title>
<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Lato" />
<link rel="stylesheet" href="style.css" />
<meta name="viewport" content="width=device-width, initial-scale=1" />
</head>
<body>
<div class="top">
<div class="back">
back to: <a href="/">Be Well Tuned</a>
</div>
<div class="tabs">
<span>Outline</span>
</div>
</div>
<div class="content">
<h1>Track Reality With Beliefs: Outline</h1>
<ul>
<li>Bets<ul>
<li>install truth as instrumental value<ul>
<li>Arguments<ul>
<li>Achieving results<ul>
<li>Armchair map-drawing doesn’t give results</li>
<li>Plans less likely to work if based on fake premises</li>
<li>Avoid wireheading (convincing yourself you’ve achieved goals)</li>
<li>You believe you have X fuel in your tank, it would be inconvenient if you had to refuel; then you get stranded</li>
<li>https://www.readthesequences.com/Why-Truth-And</li>
<li>http://lesswrong.com/lw/eqn/the_useful_idea_of_truth/</li>
<li>https://www.readthesequences.com/DoublethinkChoosingToBeBiased</li>
<li>http://lesswrong.com/lw/k7h/a_dialogue_on_doublethink/</li>
</ul>
</li>
<li>Globality/habit<ul>
<li>Cannot start truth-seeking only in certain areas (cog stra are global)</li>
<li>http://lesswrong.com/lw/uy/dark_side_epistemology/</li>
</ul>
</li>
<li>Clarity/efficiency of thought<ul>
<li>Truth-seeking thought is more efficient (seeks shortest paths to the goal)</li>
<li>Less cognitive resources wasted on deception/keeping track of multiple variants/who thinks what</li>
<li>
<ul>
<li>Asides:</li>
</ul>
</li>
</ul>
</li>
<li>http://yudkowsky.net/rational/virtues/</li>
<li>http://slatestarcodex.com/2017/03/24/guided-by-the-beauty-of-our-weapons/</li>
</ul>
</li>
</ul>
</li>
<li>Micro-bets with thought (aka logical inductors!)<ul>
<li>Clock</li>
<li>Enter the room</li>
<li>People’s reactions</li>
<li>Completion times</li>
</ul>
</li>
</ul>
</li>
<li>Biases<ul>
<li>https://www.readthesequences.com/Whats-A-Bias-Again</li>
<li>Remark on it’s enough to train a limited amount, then innovate</li>
<li>Process:<ul>
<li>Pick a bias</li>
<li>Thought experiments</li>
<li>Get real life experience + notice</li>
</ul>
</li>
<li>List<ul>
<li>Availability<ul>
<li>https://www.readthesequences.com/Availability</li>
<li>https://en.wikipedia.org/wiki/Availability_heuristic</li>
</ul>
</li>
<li>Conjunction fallacy<ul>
<li>http://lesswrong.com/lw/ji/conjunction_fallacy/</li>
<li>https://en.wikipedia.org/wiki/Conjunction_fallacy</li>
<li>Related: https://www.readthesequences.com/BurdensomeDetails</li>
</ul>
</li>
<li>Planning fallacy (+black swans?)<ul>
<li>https://www.readthesequences.com/Planning-Fallacy</li>
<li>https://en.wikipedia.org/wiki/Planning_fallacy</li>
</ul>
</li>
<li>Sunk cost fallacy<ul>
<li>https://en.wikipedia.org/wiki/Sunk_cost</li>
<li>http://lesswrong.com/lw/gx/just_lose_hope_already/</li>
</ul>
</li>
<li>Illusion of transparency<ul>
<li>https://www.readthesequences.com/Illusion-Of-Transparency-Why-No-One-Understands-You</li>
<li>https://en.wikipedia.org/wiki/Illusion_of_transparency</li>
</ul>
</li>
<li>Allais paradox<ul>
<li>http://lesswrong.com/lw/my/the_allais_paradox/</li>
<li>https://en.wikipedia.org/wiki/Allais_paradox</li>
</ul>
</li>
<li>Bucket errors<ul>
<li>http://lesswrong.com/lw/o2k/flinching_away_from_truth_is_often_about/</li>
</ul>
</li>
<li>Loss aversion<ul>
<li>http://lesswrong.com/lw/13i/shut_up_and_guess/</li>
<li>https://en.wikipedia.org/wiki/Loss_aversion</li>
</ul>
</li>
<li>Bias blind spot<ul>
<li>https://en.wikipedia.org/wiki/Bias_blind_spot</li>
</ul>
</li>
<li>Representativeness heuristic<ul>
<li>https://en.wikipedia.org/wiki/Representativeness_heuristic</li>
</ul>
</li>
<li>Base rate neglect<ul>
<li>https://en.wikipedia.org/wiki/Base_rate_fallacy</li>
</ul>
</li>
<li>???<ul>
<li>http://lesswrong.com/lw/vo/lawful_uncertainty/</li>
</ul>
</li>
<li>Survivorship bias<ul>
<li>https://en.wikipedia.org/wiki/Survivorship_bias</li>
</ul>
</li>
<li>Status quo bias<ul>
<li>https://en.wikipedia.org/wiki/Status_quo_bias</li>
<li>https://nickbostrom.com/ethics/statusquo.pdf</li>
</ul>
</li>
<li>Overconfidence<ul>
<li>https://en.wikipedia.org/wiki/Overconfidence_effect</li>
</ul>
</li>
<li>Hindsight bias<ul>
<li>http://lesswrong.com/lw/il/hindsight_bias/</li>
<li>https://en.wikipedia.org/wiki/Hindsight_bias</li>
</ul>
</li>
<li>Duration neglect<ul>
<li>https://en.wikipedia.org/wiki/Duration_neglect</li>
</ul>
</li>
<li>Dunning–Kruger effect<ul>
<li>https://en.wikipedia.org/wiki/Dunning%E2%80%93Kruger_effect</li>
</ul>
</li>
<li>Negativity bias<ul>
<li>it’s easier to notice bad/scary/ugly/attack etc.</li>
<li>https://en.wikipedia.org/wiki/Negativity_bias</li>
</ul>
</li>
<li>Bee sting fallacy<ul>
<li>http://archive.boston.com/bostonglobe/ideas/articles/2008/03/30/the_sting_of_poverty/?page=full</li>
<li>http://bearlamp.com.au/working-with-multiple-problems-at-once/</li>
<li>https://news.ycombinator.com/item?id=8425575</li>
</ul>
</li>
<li>Gambler’s fallacy<ul>
<li>https://en.wikipedia.org/wiki/Gambler%27s_fallacy</li>
</ul>
</li>
<li>Just world fallacy<ul>
<li>https://youarenotsosmart.com/2010/06/07/the-just-world-fallacy/</li>
</ul>
</li>
<li>Negative bias/confirmation bias<ul>
<li>https://en.wikipedia.org/wiki/Confirmation_bias</li>
</ul>
</li>
<li>Scope insensitivity (+ratio bias?)<ul>
<li>http://lesswrong.com/lw/hw/scope_insensitivity/</li>
</ul>
</li>
<li>Anchoring<ul>
<li>http://lesswrong.com/lw/j7/anchoring_and_adjustment/</li>
</ul>
</li>
<li>Pareidolia<ul>
<li>https://en.wikipedia.org/wiki/Pareidolia</li>
<li>Counter: explicitly try to match noise</li>
</ul>
</li>
<li>Upper bound on events based on history<ul>
<li>https://www.edge.org/conversation/nassim_nicholas_taleb-the-fourth-quadrant-a-map-of-the-limits-of-statistics</li>
</ul>
</li>
<li>Positive illusions<ul>
<li>https://en.wikipedia.org/wiki/Positive_illusions</li>
</ul>
</li>
<li>120% total effort in marriage<ul>
<li>https://www.wikiwand.com/en/Illusory_superiority</li>
<li>https://www.psychologicalscience.org/news/motr/when-it-comes-to-driving-most-people-think-their-skills-are-above-average.html</li>
<li>
<ul>
<li>Originals:</li>
</ul>
</li>
<li>Jungle bias - expecting zero-sum games/scarce resources</li>
<li>Agentization</li>
<li>Prophet’s fallacy</li>
</ul>
</li>
</ul>
</li>
<li>Install cog stra that will converge on the solution<ul>
<li>To do this: install cog stra that will notice instances (get burned on some examples) + goal to fix</li>
</ul>
</li>
</ul>
</li>
<li>Bayes<ul>
<li>Intuitive explanations of Bayes<ul>
<li>https://arbital.com/p/bayes_rule/?l=1zq</li>
<li>
<ul>
<li>http://lesswrong.com/lw/2b0/bayes_theorem_illustrated_my_way/</li>
</ul>
</li>
<li>https://www.readthesequences.com/An-Intuitive-Explanation-Of-Bayess-Theorem</li>
<li>https://arbital.com/p/bayes_rule/?l=693</li>
<li>http://acritch.com/credence/</li>
</ul>
</li>
<li>Catch updating on evidence<ul>
<li>Compare with explicit Bayesian calculation</li>
<li>Improve cog stra</li>
</ul>
</li>
</ul>
</li>
</ul>
</div>
<div class="bottom">
<div class="back">
back to: <a href="/">Be Well Tuned</a>
</div>
<p>Copyright 2017-2018 SquirrelInHell</p>
</div>
</body>
</html>
